{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import spatial\n",
    "import itertools\n",
    "\n",
    "from collections import ChainMap\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary with only the item embeddings\n",
    "\n",
    "item_embedddings = pickle.load( open( \"item_embedddings.p\", \"rb\" ) )\n",
    "#print(len(item_embedddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## slicing the dictionary\n",
    "\n",
    "sample_item_embedddings = dict(itertools.islice(item_embedddings.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this cell stores the normalized item_embeddings\n",
    "nomalized_item_embedddings = {}\n",
    "\n",
    "for k,v in item_embedddings.items():\n",
    "    v_norm = np.linalg.norm(v)\n",
    "    nomalized_item_embedddings.update({k:v_norm})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the output embeddings from LSTM\n",
    "\n",
    "output_embeddings = pickle.load( open( \"output_embeddings.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert output embedings into 1 -D\n",
    "\n",
    "new_output_embeddings = list(itertools.chain.from_iterable(output_embeddings)) \n",
    "\n",
    "sample_output_embeddings = new_output_embeddings[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "## this cell calculates the cosine similarity among y and y_hats\n",
    "final_cosine = []\n",
    "ranks = []\n",
    "\n",
    "\n",
    "for yhat in tqdm(sample_output_embeddings):  \n",
    "    local_cosine = {}\n",
    "    sorted_cosine = {}\n",
    "    rank_list = []\n",
    "    sliced_dict = {}\n",
    "    yhat_norm = np.linalg.norm(yhat)\n",
    "    original_item_embedding_values = list(item_embedddings.values())\n",
    "    count = 0\n",
    "    for k,v in nomalized_item_embedddings.items():\n",
    "        \n",
    "        # manually compute cosine similarity\n",
    "        dot = np.dot(yhat, original_item_embedding_values[count])\n",
    "        count +=1\n",
    "        result = dot / (yhat_norm * v)\n",
    "        local_cosine.update({k:result})\n",
    "   \n",
    "    sorted_cosine = {k: v for k, v in sorted(local_cosine.items(), key=lambda item: -item[1])}\n",
    "    sliced_dict = dict(itertools.islice(sorted_cosine.items(), 50))  ## take top 50 prediction for each item\n",
    "    \n",
    "    rank_list = list(sliced_dict.keys())\n",
    "    with open('ranks_index.p', 'ab') as f:\n",
    "        pickle.dump(rank_list, f)\n",
    "    del original_item_embedding_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this cell captures the top n ranked predicted items\n",
    "with open('ranks_index.p', 'rb') as f: \n",
    "    y_hat = [pickle.load(f) for j in range(len(new_output_embeddings))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load original y labels\n",
    "\n",
    "num_y_test = pickle.load( open( \"original_output_embeddings.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load original keys of y\n",
    "y = []\n",
    "original_output_embeddings = num_y_test.tolist()\n",
    "\n",
    "\n",
    "for i in original_output_embeddings:\n",
    "    for k,v in item_embedddings.items():\n",
    "        if i ==v:\n",
    "            y.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is to generate the matrix for final learning\n",
    "## so if original label is present in top n prediction labels , increase the count by 1\n",
    "y_arr = [None]* len(y)\n",
    "y_hat_arr = [None]* len(y_hat)\n",
    "y_arr = y\n",
    "y_hat_arr = y_hat\n",
    "\n",
    "i = 0\n",
    "count = 0\n",
    "while(i<len(y_arr)):\n",
    "    if (y_arr[i] in y_hat_arr[i]):\n",
    "        count +=1\n",
    "    i +=1\n",
    "Ratio = count/len(y_arr)\n",
    "print('Learning Ratio is : ',Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
